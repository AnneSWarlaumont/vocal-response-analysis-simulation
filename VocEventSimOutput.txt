[1] "Simulation parameters:"
[1] "response threshold: 1"
[1] "agent 1 (i.e. infant) other sensitivity: 1"
[1] "agent 1 response sensitivity: 1"
[1] "agent 2 (i.e. adult) other sensitivity: 1"
[1] "agent 2 response sensitivity: 1"
[1] "* The values indicate the factor that probability of vocalizing is multiplied by after the other agent vocalizes or responds. 1 is thus completely insensitive and higher values indicate higher degrees of sensitivity."

Call:
lm(formula = scale(log(ivi_records)) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.2218 -0.6913 -0.1608  0.5404  6.0361 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.087308   0.002352  37.127  < 2e-16 ***
ivi_response_records -0.032019   0.010912  -2.934  0.00334 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.047 on 207942 degrees of freedom
  (58268 observations deleted due to missingness)
Multiple R-squared:  4.14e-05,	Adjusted R-squared:  3.659e-05 
F-statistic: 8.609 on 1 and 207942 DF,  p-value: 0.003345


Call:
lm(formula = scale(previvi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4992 -0.6007 -0.1158  0.4543  6.9430 

Coefficients:
                       Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.3125261  0.0020087 155.587   <2e-16 ***
ivi_response_records -0.0009762  0.0093211  -0.105    0.917    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.8945 on 207942 degrees of freedom
  (58268 observations deleted due to missingness)
Multiple R-squared:  5.275e-08,	Adjusted R-squared:  -4.756e-06 
F-statistic: 0.01097 on 1 and 207942 DF,  p-value: 0.9166


Call:
lm(formula = scale(prev3ivi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5612 -0.7538 -0.0778  0.6040  6.9776 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)          -0.017369   0.002331  -7.453 9.18e-14 ***
ivi_response_records -0.021942   0.010812  -2.029   0.0424 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.037 on 207561 degrees of freedom
  (58649 observations deleted due to missingness)
Multiple R-squared:  1.984e-05,	Adjusted R-squared:  1.503e-05 
F-statistic: 4.119 on 1 and 207561 DF,  p-value: 0.04241


SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.105596 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1055.96 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 1230.71 seconds (Warm-up)
Chain 1:                1205.5 seconds (Sampling)
Chain 1:                2436.2 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0.105193 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1051.93 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 1213.21 seconds (Warm-up)
Chain 2:                1223.53 seconds (Sampling)
Chain 2:                2436.74 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 0.108755 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1087.55 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 1750.72 seconds (Warm-up)
Chain 3:                1869.45 seconds (Sampling)
Chain 3:                3620.17 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 0.145149 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1451.49 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 2005.03 seconds (Warm-up)
Chain 4:                3850.7 seconds (Sampling)
Chain 4:                5855.72 seconds (Total)
Chain 4: 

Call:
glm(formula = a1_voc_record ~ scale(log(timessince_last_a1)) + 
    scale(log(timessince_2ndToLast_a1)) + scale(log(timessince_3rdToLast_a1)), 
    family = "binomial", data = timessince_df, na.action = na.exclude)

Coefficients:
                                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)                         -5.040375   0.005530 -911.45   <2e-16 ***
scale(log(timessince_last_a1))      -0.624143   0.006935  -90.00   <2e-16 ***
scale(log(timessince_2ndToLast_a1)) -0.484041   0.011268  -42.96   <2e-16 ***
scale(log(timessince_3rdToLast_a1)) -0.958624   0.009315 -102.91   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2275196  on 7178141  degrees of freedom
Residual deviance: 1579131  on 7178138  degrees of freedom
  (21858 observations deleted due to missingness)
AIC: 1579139

Number of Fisher Scoring iterations: 8


Call:
lm(formula = a1_resids ~ scale(log(timessince_last_a2)) + scale(log(timessince_2ndToLast_a2)) + 
    scale(log(timessince_3rdToLast_a2)), data = timessince_df, 
    na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.9907 -0.1107  0.0144  0.0488  4.2740 

Coefficients:
                                      Estimate Std. Error  t value Pr(>|t|)    
(Intercept)                         -0.0948490  0.0001714 -553.424  < 2e-16 ***
scale(log(timessince_last_a2))      -0.0016723  0.0004445   -3.762 0.000169 ***
scale(log(timessince_2ndToLast_a2)) -0.0003532  0.0008375   -0.422 0.673217    
scale(log(timessince_3rdToLast_a2))  0.0024875  0.0006964    3.572 0.000354 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.4588 on 7166716 degrees of freedom
  (33280 observations deleted due to missingness)
Multiple R-squared:  5.375e-06,	Adjusted R-squared:  4.957e-06 
F-statistic: 12.84 on 3 and 7166716 DF,  p-value: 2.191e-08


Call:
glm(formula = a1_voc_record ~ scale(log(a1_weighted_histories + 
    1)) + scale(log(a2_weighted_histories + 1)) + scale(log(a2toa1_r_weighted_histories + 
    1)), family = "binomial", data = timessince_df[61:nrow(timessince_df), 
    ], na.action = na.exclude)

Coefficients:
                                             Estimate Std. Error  z value Pr(>|z|)    
(Intercept)                                 -4.342541   0.003801 -1142.57   <2e-16 ***
scale(log(a1_weighted_histories + 1))        1.302637   0.001952   667.26   <2e-16 ***
scale(log(a2_weighted_histories + 1))        0.069434   0.003061    22.68   <2e-16 ***
scale(log(a2toa1_r_weighted_histories + 1)) -0.038447   0.001479   -25.99   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2266331  on 7187999  degrees of freedom
Residual deviance: 1615824  on 7187996  degrees of freedom
  (11940 observations deleted due to missingness)
AIC: 1615832

Number of Fisher Scoring iterations: 7

 Family: poisson 
  Links: mu = log 
Formula: a1_voc_record ~ scale(log(a1_weighted_histories + 1)) + scale(log(a2_weighted_histories + 1)) + scale(log(a2toa1_r_weighted_histories + 1)) 
   Data: timessince_df[61:nrow(timessince_df), ] (Number of observations: 7188000) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
                                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept                                -4.33      0.00    -4.34    -4.32 1.00     1286     1624
scaleloga1_weighted_historiesP1           1.17      0.00     1.17     1.17 1.00     1372     2057
scaleloga2_weighted_historiesP1           0.07      0.00     0.06     0.07 1.00     1828     1859
scaleloga2toa1_r_weighted_historiesP1    -0.03      0.00    -0.04    -0.03 1.00     2297     2450

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).

Call:
glm(formula = a1_voc_record ~ scale(log(a1_weighted_histories + 
    1)), family = "binomial", data = timessince_df, na.action = na.exclude)

Coefficients:
                                       Estimate Std. Error z value Pr(>|z|)    
(Intercept)                           -4.337974   0.003787 -1145.5   <2e-16 ***
scale(log(a1_weighted_histories + 1))  1.285072   0.001828   702.9   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2266331  on 7187999  degrees of freedom
Residual deviance: 1616541  on 7187998  degrees of freedom
  (12000 observations deleted due to missingness)
AIC: 1616545

Number of Fisher Scoring iterations: 7


Call:
lm(formula = scale(a1_wh_resids) ~ scale(log(a2_weighted_histories + 
    1)), data = timessince_df, na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.7723 -0.0927 -0.0007  0.0006  7.1549 

Coefficients:
                                        Estimate Std. Error t value Pr(>|t|)    
(Intercept)                           -1.193e-11  3.730e-04   0.000        1    
scale(log(a2_weighted_histories + 1))  2.111e-03  3.730e-04   5.659 1.52e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1 on 7187998 degrees of freedom
  (12000 observations deleted due to missingness)
Multiple R-squared:  4.455e-06,	Adjusted R-squared:  4.316e-06 
F-statistic: 32.02 on 1 and 7187998 DF,  p-value: 1.525e-08


Call:
lm(formula = scale(a2_wh_resids) ~ scale(log(a2toa1_r_weighted_histories + 
    1)), data = timessince_df, na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.7568 -0.0919 -0.0058 -0.0046  7.1498 

Coefficients:
                                              Estimate Std. Error t value Pr(>|t|)    
(Intercept)                                 -1.351e-14  3.729e-04    0.00        1    
scale(log(a2toa1_r_weighted_histories + 1)) -2.721e-02  3.729e-04  -72.99   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9996 on 7187998 degrees of freedom
  (12000 observations deleted due to missingness)
Multiple R-squared:  0.0007406,	Adjusted R-squared:  0.0007404 
F-statistic:  5327 on 1 and 7187998 DF,  p-value: < 2.2e-16

[1] "Simulation parameters:"
[1] "response threshold: 1"
[1] "agent 1 (i.e. infant) other sensitivity: 1"
[1] "agent 1 response sensitivity: 1.5"
[1] "agent 2 (i.e. adult) other sensitivity: 1"
[1] "agent 2 response sensitivity: 1"
[1] "* The values indicate the factor that probability of vocalizing is multiplied by after the other agent vocalizes or responds. 1 is thus completely insensitive and higher values indicate higher degrees of sensitivity."

Call:
lm(formula = scale(log(ivi_records)) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.2107 -0.6665 -0.1223  0.5143  6.5696 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.092561   0.002275   40.69   <2e-16 ***
ivi_response_records -0.107483   0.009733  -11.04   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.05 on 225556 degrees of freedom
  (66776 observations deleted due to missingness)
Multiple R-squared:  0.0005404,	Adjusted R-squared:  0.000536 
F-statistic:   122 on 1 and 225556 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(previvi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.6739 -0.5929 -0.1170  0.4515  6.8356 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.337624   0.001930  174.91   <2e-16 ***
ivi_response_records -0.214535   0.008259  -25.98   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.8914 on 225556 degrees of freedom
  (66776 observations deleted due to missingness)
Multiple R-squared:  0.002982,	Adjusted R-squared:  0.002978 
F-statistic: 674.7 on 1 and 225556 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(prev3ivi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.4459 -0.7606 -0.0798  0.6029  7.1164 

Coefficients:
                     Estimate Std. Error t value Pr(>|t|)    
(Intercept)          -0.01464    0.00225   -6.51 7.54e-11 ***
ivi_response_records -0.12367    0.00962  -12.86  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.038 on 225184 degrees of freedom
  (67148 observations deleted due to missingness)
Multiple R-squared:  0.0007333,	Adjusted R-squared:  0.0007289 
F-statistic: 165.3 on 1 and 225184 DF,  p-value: < 2.2e-16


SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.136735 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1367.35 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 2486.91 seconds (Warm-up)
Chain 1:                1504.07 seconds (Sampling)
Chain 1:                3990.98 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0.12891 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1289.1 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 1601.62 seconds (Warm-up)
Chain 2:                8255.33 seconds (Sampling)
Chain 2:                9856.96 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 0.107884 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1078.84 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 1277.21 seconds (Warm-up)
Chain 3:                1291.93 seconds (Sampling)
Chain 3:                2569.14 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 0.120336 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1203.36 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 10074.3 seconds (Warm-up)
Chain 4:                5170.92 seconds (Sampling)
Chain 4:                15245.2 seconds (Total)
Chain 4: 

Call:
glm(formula = a1_voc_record ~ scale(log(timessince_last_a1)) + 
    scale(log(timessince_2ndToLast_a1)) + scale(log(timessince_3rdToLast_a1)), 
    family = "binomial", data = timessince_df, na.action = na.exclude)

Coefficients:
                                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)                         -4.974908   0.005418 -918.17   <2e-16 ***
scale(log(timessince_last_a1))      -0.638958   0.006932  -92.18   <2e-16 ***
scale(log(timessince_2ndToLast_a1)) -0.470161   0.011271  -41.71   <2e-16 ***
scale(log(timessince_3rdToLast_a1)) -1.010752   0.009353 -108.06   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2442556  on 7175245  degrees of freedom
Residual deviance: 1686941  on 7175242  degrees of freedom
  (24754 observations deleted due to missingness)
AIC: 1686949

Number of Fisher Scoring iterations: 8


Call:
lm(formula = a1_resids ~ scale(log(timessince_last_a2)) + scale(log(timessince_2ndToLast_a2)) + 
    scale(log(timessince_3rdToLast_a2)), data = timessince_df, 
    na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0066 -0.1209  0.0141  0.0504  4.3767 

Coefficients:
                                      Estimate Std. Error  t value Pr(>|t|)    
(Intercept)                         -0.0959518  0.0001774 -540.882  < 2e-16 ***
scale(log(timessince_last_a2))      -0.0016860  0.0004658   -3.620 0.000295 ***
scale(log(timessince_2ndToLast_a2)) -0.0023860  0.0008551   -2.790 0.005265 ** 
scale(log(timessince_3rdToLast_a2))  0.0023796  0.0007094    3.354 0.000796 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.4746 on 7158860 degrees of freedom
  (41136 observations deleted due to missingness)
Multiple R-squared:  1.56e-05,	Adjusted R-squared:  1.518e-05 
F-statistic: 37.23 on 3 and 7158860 DF,  p-value: < 2.2e-16


Call:
glm(formula = a1_voc_record ~ scale(log(a1_weighted_histories + 
    1)) + scale(log(a2_weighted_histories + 1)) + scale(log(a2toa1_r_weighted_histories + 
    1)), family = "binomial", data = timessince_df[61:nrow(timessince_df), 
    ], na.action = na.exclude)

Coefficients:
                                             Estimate Std. Error  z value Pr(>|z|)    
(Intercept)                                 -4.269001   0.003713 -1149.65   <2e-16 ***
scale(log(a1_weighted_histories + 1))        1.336818   0.001986   672.97   <2e-16 ***
scale(log(a2_weighted_histories + 1))        0.055632   0.002950    18.86   <2e-16 ***
scale(log(a2toa1_r_weighted_histories + 1)) -0.022444   0.001456   -15.41   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2434174  on 7187999  degrees of freedom
Residual deviance: 1724809  on 7187996  degrees of freedom
  (11940 observations deleted due to missingness)
AIC: 1724817

Number of Fisher Scoring iterations: 7

 Family: poisson 
  Links: mu = log 
Formula: a1_voc_record ~ scale(log(a1_weighted_histories + 1)) + scale(log(a2_weighted_histories + 1)) + scale(log(a2toa1_r_weighted_histories + 1)) 
   Data: timessince_df[61:nrow(timessince_df), ] (Number of observations: 7188000) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
                                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept                                -4.26      0.00    -4.27    -4.25 1.00     1603     1502
scaleloga1_weighted_historiesP1           1.20      0.00     1.20     1.20 1.00     1651     1576
scaleloga2_weighted_historiesP1           0.06      0.00     0.05     0.06 1.00     2152     2201
scaleloga2toa1_r_weighted_historiesP1    -0.03      0.00    -0.03    -0.02 1.00     2324     2374

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).

Call:
glm(formula = a1_voc_record ~ scale(log(a1_weighted_histories + 
    1)), family = "binomial", data = timessince_df, na.action = na.exclude)

Coefficients:
                                       Estimate Std. Error z value Pr(>|z|)    
(Intercept)                           -4.265614   0.003699   -1153   <2e-16 ***
scale(log(a1_weighted_histories + 1))  1.326444   0.001840     721   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2434174  on 7187999  degrees of freedom
Residual deviance: 1725167  on 7187998  degrees of freedom
  (12000 observations deleted due to missingness)
AIC: 1725171

Number of Fisher Scoring iterations: 7


Call:
lm(formula = scale(a1_wh_resids) ~ scale(log(a2_weighted_histories + 
    1)), data = timessince_df, na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.7416 -0.1034 -0.0015  0.0013  6.9027 

Coefficients:
                                        Estimate Std. Error t value Pr(>|t|)    
(Intercept)                           -2.288e-11  3.730e-04    0.00        1    
scale(log(a2_weighted_histories + 1))  4.207e-03  3.730e-04   11.28   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1 on 7187998 degrees of freedom
  (12000 observations deleted due to missingness)
Multiple R-squared:  1.77e-05,	Adjusted R-squared:  1.756e-05 
F-statistic: 127.2 on 1 and 7187998 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(a2_wh_resids) ~ scale(log(a2toa1_r_weighted_histories + 
    1)), data = timessince_df, na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.7447 -0.1051 -0.0045 -0.0018  6.8997 

Coefficients:
                                              Estimate Std. Error t value Pr(>|t|)    
(Intercept)                                 -3.138e-14  3.729e-04    0.00        1    
scale(log(a2toa1_r_weighted_histories + 1)) -1.508e-02  3.729e-04  -40.42   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9999 on 7187998 degrees of freedom
  (12000 observations deleted due to missingness)
Multiple R-squared:  0.0002273,	Adjusted R-squared:  0.0002271 
F-statistic:  1634 on 1 and 7187998 DF,  p-value: < 2.2e-16

[1] "Simulation parameters:"
[1] "response threshold: 1"
[1] "agent 1 (i.e. infant) other sensitivity: 1.5"
[1] "agent 1 response sensitivity: 1"
[1] "agent 2 (i.e. adult) other sensitivity: 1"
[1] "agent 2 response sensitivity: 1"
[1] "* The values indicate the factor that probability of vocalizing is multiplied by after the other agent vocalizes or responds. 1 is thus completely insensitive and higher values indicate higher degrees of sensitivity."

Call:
lm(formula = scale(log(ivi_records)) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.2060 -0.9406 -0.1411  0.5308  7.2974 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.091652   0.001409   65.07   <2e-16 ***
ivi_response_records -0.265431   0.004744  -55.96   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.047 on 606080 degrees of freedom
  (224931 observations deleted due to missingness)
Multiple R-squared:  0.00514,	Adjusted R-squared:  0.005138 
F-statistic:  3131 on 1 and 606080 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(previvi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.2972 -0.5728 -0.1286  0.4427  7.5145 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.435733   0.001134  384.27   <2e-16 ***
ivi_response_records -0.258448   0.003819  -67.68   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.8429 on 606080 degrees of freedom
  (224931 observations deleted due to missingness)
Multiple R-squared:  0.007501,	Adjusted R-squared:  0.007499 
F-statistic:  4581 on 1 and 606080 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(prev3ivi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.9740 -0.8394 -0.0779  0.6473  7.7502 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)          -0.010373   0.001389  -7.469 8.11e-14 ***
ivi_response_records -0.190046   0.004676 -40.642  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.032 on 605728 degrees of freedom
  (225283 observations deleted due to missingness)
Multiple R-squared:  0.002719,	Adjusted R-squared:  0.002718 
F-statistic:  1652 on 1 and 605728 DF,  p-value: < 2.2e-16


SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.115272 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1152.72 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 3827.54 seconds (Warm-up)
Chain 1:                3319.91 seconds (Sampling)
Chain 1:                7147.45 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0.109062 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1090.62 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 1248.57 seconds (Warm-up)
Chain 2:                2218.53 seconds (Sampling)
Chain 2:                3467.1 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 0.112544 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1125.44 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 1322.94 seconds (Warm-up)
Chain 3:                1464.49 seconds (Sampling)
Chain 3:                2787.43 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 0.130939 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 1309.39 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 3914.16 seconds (Warm-up)
Chain 4:                1243.95 seconds (Sampling)
Chain 4:                5158.1 seconds (Total)
Chain 4: 

Call:
glm(formula = a1_voc_record ~ scale(log(timessince_last_a1)) + 
    scale(log(timessince_2ndToLast_a1)) + scale(log(timessince_3rdToLast_a1)), 
    family = "binomial", data = timessince_df, na.action = na.exclude)

Coefficients:
                                     Estimate Std. Error  z value Pr(>|z|)    
(Intercept)                         -2.956541   0.002409 -1227.35   <2e-16 ***
scale(log(timessince_last_a1))      -0.449179   0.004486  -100.12   <2e-16 ***
scale(log(timessince_2ndToLast_a1)) -0.359216   0.007358   -48.82   <2e-16 ***
scale(log(timessince_3rdToLast_a1)) -1.007019   0.006256  -160.98   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 5149143  on 7196468  degrees of freedom
Residual deviance: 4125146  on 7196465  degrees of freedom
  (3531 observations deleted due to missingness)
AIC: 4125154

Number of Fisher Scoring iterations: 7


Call:
lm(formula = a1_resids ~ scale(log(timessince_last_a2)) + scale(log(timessince_2ndToLast_a2)) + 
    scale(log(timessince_3rdToLast_a2)), data = timessince_df, 
    na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0657 -0.4432 -0.1009  0.0618  3.9869 

Coefficients:
                                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)                         -0.1394604  0.0002775 -502.52   <2e-16 ***
scale(log(timessince_last_a2))      -0.0293249  0.0007002  -41.88   <2e-16 ***
scale(log(timessince_2ndToLast_a2)) -0.0217833  0.0012729  -17.11   <2e-16 ***
scale(log(timessince_3rdToLast_a2))  0.0157016  0.0010547   14.89   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.7433 on 7173525 degrees of freedom
  (26471 observations deleted due to missingness)
Multiple R-squared:  0.002322,	Adjusted R-squared:  0.002322 
F-statistic:  5566 on 3 and 7173525 DF,  p-value: < 2.2e-16


Call:
glm(formula = a1_voc_record ~ scale(log(a1_weighted_histories + 
    1)) + scale(log(a2_weighted_histories + 1)) + scale(log(a2toa1_r_weighted_histories + 
    1)), family = "binomial", data = timessince_df[61:nrow(timessince_df), 
    ], na.action = na.exclude)

Coefficients:
                                             Estimate Std. Error z value Pr(>|z|)    
(Intercept)                                 -2.774025   0.002093 -1325.3   <2e-16 ***
scale(log(a1_weighted_histories + 1))        1.384176   0.001994   694.2   <2e-16 ***
scale(log(a2_weighted_histories + 1))        0.288025   0.001748   164.8   <2e-16 ***
scale(log(a2toa1_r_weighted_histories + 1)) -0.183740   0.001567  -117.2   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 5137468  on 7187999  degrees of freedom
Residual deviance: 4106254  on 7187996  degrees of freedom
  (11940 observations deleted due to missingness)
AIC: 4106262

Number of Fisher Scoring iterations: 6

 Family: poisson 
  Links: mu = log 
Formula: a1_voc_record ~ scale(log(a1_weighted_histories + 1)) + scale(log(a2_weighted_histories + 1)) + scale(log(a2toa1_r_weighted_histories + 1)) 
   Data: timessince_df[61:nrow(timessince_df), ] (Number of observations: 7188000) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
                                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept                                -2.87      0.00    -2.87    -2.86 1.00     1699     1625
scaleloga1_weighted_historiesP1           1.20      0.00     1.20     1.21 1.00     1694     1640
scaleloga2_weighted_historiesP1           0.23      0.00     0.22     0.23 1.00     2109     2126
scaleloga2toa1_r_weighted_historiesP1    -0.15      0.00    -0.15    -0.15 1.00     2272     2416

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).

Call:
glm(formula = a1_voc_record ~ scale(log(a1_weighted_histories + 
    1)), family = "binomial", data = timessince_df, na.action = na.exclude)

Coefficients:
                                       Estimate Std. Error z value Pr(>|z|)    
(Intercept)                           -2.755970   0.002062 -1336.5   <2e-16 ***
scale(log(a1_weighted_histories + 1))  1.428902   0.001810   789.4   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 5137468  on 7187999  degrees of freedom
Residual deviance: 4132519  on 7187998  degrees of freedom
  (12000 observations deleted due to missingness)
AIC: 4132523

Number of Fisher Scoring iterations: 6


Call:
lm(formula = scale(a1_wh_resids) ~ scale(log(a2_weighted_histories + 
    1)), data = timessince_df, na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.6164 -0.5737 -0.0720  0.0071  4.1745 

Coefficients:
                                        Estimate Std. Error t value Pr(>|t|)    
(Intercept)                           -4.416e-12  3.725e-04     0.0        1    
scale(log(a2_weighted_histories + 1))  5.158e-02  3.725e-04   138.5   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9987 on 7187998 degrees of freedom
  (12000 observations deleted due to missingness)
Multiple R-squared:  0.00266,	Adjusted R-squared:  0.00266 
F-statistic: 1.917e+04 on 1 and 7187998 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(a2_wh_resids) ~ scale(log(a2toa1_r_weighted_histories + 
    1)), data = timessince_df, na.action = na.exclude)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.5877 -0.5786 -0.0819 -0.0027  4.1703 

Coefficients:
                                              Estimate Std. Error t value Pr(>|t|)    
(Intercept)                                 -6.371e-14  3.729e-04    0.00        1    
scale(log(a2toa1_r_weighted_histories + 1)) -2.393e-02  3.729e-04  -64.17   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9997 on 7187998 degrees of freedom
  (12000 observations deleted due to missingness)
Multiple R-squared:  0.0005725,	Adjusted R-squared:  0.0005724 
F-statistic:  4118 on 1 and 7187998 DF,  p-value: < 2.2e-16

[1] "Simulation parameters:"
[1] "response threshold: 1"
[1] "agent 1 (i.e. infant) other sensitivity: 1.5"
[1] "agent 1 response sensitivity: 1.5"
[1] "agent 2 (i.e. adult) other sensitivity: 1"
[1] "agent 2 response sensitivity: 1"
[1] "* The values indicate the factor that probability of vocalizing is multiplied by after the other agent vocalizes or responds. 1 is thus completely insensitive and higher values indicate higher degrees of sensitivity."

Call:
lm(formula = scale(log(ivi_records)) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.2043 -0.9333 -0.1266  0.5534  7.4060 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.091462   0.001388   65.91   <2e-16 ***
ivi_response_records -0.271017   0.004622  -58.64   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.047 on 625537 degrees of freedom
  (234781 observations deleted due to missingness)
Multiple R-squared:  0.005467,	Adjusted R-squared:  0.005465 
F-statistic:  3439 on 1 and 625537 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(previvi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.1156 -0.5752 -0.1291  0.4449  7.7433 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)           0.442937   0.001114  397.70   <2e-16 ***
ivi_response_records -0.284031   0.003709  -76.57   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.8402 on 625537 degrees of freedom
  (234781 observations deleted due to missingness)
Multiple R-squared:  0.009286,	Adjusted R-squared:  0.009285 
F-statistic:  5863 on 1 and 625537 DF,  p-value: < 2.2e-16


Call:
lm(formula = scale(prev3ivi_resids) ~ ivi_response_records)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.1822 -0.8408 -0.0777  0.6456  7.9606 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)          -0.009137   0.001367  -6.682 2.36e-11 ***
ivi_response_records -0.197544   0.004553 -43.387  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.031 on 625188 degrees of freedom
  (235130 observations deleted due to missingness)
Multiple R-squared:  0.003002,	Adjusted R-squared:  0.003 
F-statistic:  1882 on 1 and 625188 DF,  p-value: < 2.2e-16


SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.110999 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1109.99 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
